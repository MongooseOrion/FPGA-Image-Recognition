# 集创赛工作规划

要在 FPGA 上使用 RISC-V 构建一个图像识别系统，遵循以下步骤：

  1. 确定 FPGA 硬件平台和 RISC-V 处理器架构，并选择合适的 RISC-V 处理器核心和外设；
  2. 下载和安装适当版本的 RISC-V 交叉编译工具链，并使用它来编译 RISC-V 处理器核心和外设所需的代码和库。此外，还需要为 TensorFlow Lite 编译适当的库和应用程序，以便在 RISC-V 处理器上运行 TensorFlow Lite 模型；
  3. 将编译后的 RISC-V 处理器核心和外设代码加载到 FPGA 中，并配置适当的内存映射和 I/O 接口。在此过程中，需要了解 FPGA 硬件平台的架构和资源限制，并根据应用程序进行优化；
  4. 使用 TensorFlow Lite 工具链将已训练的模型转换为 TensorFlow Lite 格式，并将其编译为适当的库和应用程序。然后，将编译后的库和应用程序部署到 RISC-V 处理器上。

## 软硬件划分

### 硬件层面

  1. 硬件平台选择和设计：选择合适的 FPGA 硬件平台，并根据应用程序需求进行硬件平台设计和布局。这通常需要使用硬件描述语言（例如 Verilog 或 VHDL）进行设计和开发；
  2. 外设和接口设计：确定和设计外设和接口，例如摄像头接口、SDRAM 控制器、UART 接口等等。这些外设和接口的设计也需要使用硬件描述语言进行开发；
  3. 内存映射和 I/O 接口设计：根据硬件平台和外设需求设计内存映射和 I/O 接口，并将它们映射到 FPGA 芯片的物理资源上。这也需要使用硬件描述语言进行开发；
  4. RTL验证和仿真：使用仿真工具验证硬件设计的正确性和性能。这通常需要使用硬件描述语言和仿真工具（例如 ModelSim）进行验证和仿真。

### 软件层面

  1. RISC-V 处理器核心和外设驱动程序开发：使用 RISC-V 交叉编译工具链编写 RISC-V 处理器核心和外设驱动程序的代码。这些代码可以使用汇编语言或C语言进行编写；
  2. TensorFlow Lite 库和应用程序编译：使用 RISC-V 交叉编译工具链编译 TensorFlow Lite 库和应用程序。这通常需要使用 C 语言进行编写和编译；
  3. 系统集成和测试：将硬件设计和软件开发进行集成，并进行系统级测试和调试。这可以使用 FPGA 开发板和调试工具进行测试和调试。

具体的硬件和软件工作分配可能视具体情况有所变更。

### ARM 与 RISC-V 的特点

将 TensorFlow Lite 部署到 ARM Cortex-M3 和 RISC-V 都需要进行交叉编译和移植，这两个任务的难度和工作量都相对较高。不过，根据具体的应用场景和开发需求，可能会有一些差异。

RISC-V 处理器架构比 ARM Cortex-M3 更加灵活和可定制化，因此在构建定制化的处理器和应用程序时，RISC-V 可能会更具有优势。此外，由于 RISC-V 采用的是开放式标准，因此其生态系统和社区支持也比较丰富，可以更容易地获得相关的工具链和开发资源。

然而，ARM Cortex-M3 处理器是非常流行的嵌入式处理器之一，因此在某些特定的应用场景下，ARM Cortex-M3 也可能是更好的选择。此外，ARM Cortex-M3 的处理器架构也非常成熟，并且有很多现成的工具和软件库可以使用，这可能会降低部署 TensorFlow Lite 的工作量。

将 TensorFlow Lite 部署到 ARM Cortex-M3 和 RISC-V 都需要进行大量的工作，具体的工作量取决于具体的应用场景和开发需求。

## 功能定义

该系统允许采用摄像头和（或）本地视频（例如 SD 卡）采集视频图像，然后利用 FPGA 系统本地识别视频中包含的物体。物体名称或混合视频（识别框体显示在原视频上层）可通过 HDMI 或 PCIe 输出。

### 神经网络训练
利用 PC 训练用于识别物体的参数，结果将转换为 TensorFlow Lite、Paddle-Lite 等具备交叉编译工具链的模型，以便部署在基于 RISC-V 的微处理控制系统上。

可用于该系统的训练集包括：
  1. yolov3-tiny
  2. SSD-MobileNet

### 神经网络部署
Paddle-Lite 和 TensorFlow Lite 都提供了基于 RISC-V 架构的 CPU 版本，能够在 RISC-V 平台上进行深度学习推理任务。两者都提供了丰富的 API 和示例，以帮助用户快速集成和部署深度学习模型。由于 RISC-V 平台的计算性能和内存容量等限制，可能需要针对具体的应用场景进行模型剪枝和量化等优化措施，以获得更好的性能和效果。因此，选择Paddle-Lite还是TensorFlow Lite主要取决于具体需求和应用场景，以及各自的优势和特点。例如，Paddle-Lite 在端侧部署方面具有较高的灵活性和定制化能力，而 TensorFlow Lite 在移动端部署方面具有较高的成熟度和广泛的应用场景。